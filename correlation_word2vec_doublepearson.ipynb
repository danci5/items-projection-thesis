{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import re\n",
    "os.chdir('/home/daniel/school/BP')\n",
    "from pythesis.data.prepare_data import *\n",
    "\n",
    "slova_po_b = pd.read_csv('data/processed/vyjmenovana_slova_po_b.csv')\n",
    "model = Word2Vec.load('pythesis/utils/word2vec.model') \n",
    "\n",
    "def get_word2vec_items_tuple(model, data):\n",
    "    \"\"\"Function to get all the items you need for manipulating items when working your word2vec model.\n",
    "    Returns the data which is only in the vocabulary of your model.\n",
    "    \n",
    "    Parameter 'model' is instantiated Word2vecmodel you loaded before.\n",
    "    Parameter 'data' has to have 'correct_answer', 'question' columns.\n",
    "    \n",
    "    Returns 4-tuple of word vectors array which can be then input into projection methods,\n",
    "    labels which can annotate the point in the visualization, full solutions, \n",
    "    and solutions which contain only the 'fill-in-the-blank' word.\"\"\"\n",
    "\n",
    "    data = data.drop_duplicates(subset=['question'], keep='first')\n",
    "\n",
    "    X, labels = [], []\n",
    "    solutions_vocab, full_solutions_vocab = [], []\n",
    "    solutions = get_solutions(data, method='fillin')\n",
    "    full_solutions = get_solutions(data, method='full')\n",
    "\n",
    "    for full_solution, solution, label in zip(full_solutions, solutions, data['question']):\n",
    "        try:\n",
    "            # in slova_po_b is the word 'bicí' a big outlier in visualization, i'd rather get rid of it\n",
    "            # if solution == 'bicí':\n",
    "            #     continue\n",
    "            X.append(model.wv[solution])\n",
    "            labels.append(label)\n",
    "            solutions_vocab.append(solution)\n",
    "            full_solutions_vocab.append(full_solution)\n",
    "        except KeyError as e:\n",
    "            print(\"Word '{}' is not in vocabulary of your model, therefore it won't be in your visualization.\".format(solution))\n",
    "    return X, labels, solutions_vocab, full_solutions_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'Bystrouška' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'zabydlený' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'Bystřice' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'vybydlený' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'Pardubice' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'Přibyslav' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'Robinson' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'obydlit' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'zbystřit' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'zabydlit' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'bystřit' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'odbily' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'bytelný' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'odbily' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'nerozbitný' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'dobilo' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'ledabylý' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'dobili' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'Libye' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'nevybyl' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'ubýt' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'Babylon' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'sbít' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'Kobylisy' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'odrobinka' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'nepřebývaly' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'bydla' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'bývat' is not in vocabulary of your model, therefore it won't be in your visualization.\n",
      "Word 'bicepsy' is not in vocabulary of your model, therefore it won't be in your visualization.\n"
     ]
    }
   ],
   "source": [
    "X, labels, solutions, full_solutions = get_word2vec_items_tuple(model, slova_po_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2vec_similarity_matrix(full_solutions, solutions):\n",
    "    \"\"\"'solutions' contain only the 'fill-in-the-blank' word based on which is the similarity computed.\n",
    "    'full_solutions' are for representing the assignment in matrix (same word can occur multiple times).\n",
    "    \n",
    "    Returns similarity matrix.\"\"\"\n",
    "    dataframe = pd.DataFrame(index=full_solutions,columns=full_solutions)\n",
    "    for i, j in zip(solutions, full_solutions):\n",
    "        for k, l in zip(solutions, full_solutions):\n",
    "                dataframe.loc[j,l] = model.wv.similarity(i, k)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = create_word2vec_similarity_matrix(full_solutions, solutions)\n",
    "dataframe.to_csv('data/processed/trololol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_similarity_matrix = pd.read_csv('data/processed/word2vec_words_similarity_matrix_slova_po_b.csv', index_col=0)\n",
    "word2vec_similarity_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "slova_po_b = pd.read_csv('data/processed/vyjmenovana_slova_po_b.csv')\n",
    "\n",
    "# only words which are also in my word2vec model\n",
    "vyjm_slova_filtered = slova_po_b.loc[slova_po_b['question'].isin(labels)]\n",
    "correctness_matrix = reshape_to_correctness_matrix(vyjm_slova_filtered)\n",
    "similarity_matrix = correctness_matrix_to_similarity_matrix('doublepearson', correctness_matrix)\n",
    "similarity_matrix2 = correctness_matrix_to_similarity_matrix('pearson', correctness_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 239, 239)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(similarity_matrix), len(similarity_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix.columns = data.columns\n",
    "similarity_matrix.index = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04083208545254325"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix['sbírka známek'].corr(data['bývalý'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_doublepear = pd.Series(similarity_matrix.values.flatten())\n",
    "sim_matrix_pear = pd.Series(similarity_matrix2.values.flatten())\n",
    "sim_matrix_word2vector = pd.Series(data.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8858815250933174"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix_doublepear.corr(sim_matrix_pear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23676038278328249"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix_pear.corr(sim_matrix_word2vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14759275116284798"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix_doublepear.corr(sim_matrix_word2vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.88588153, 0.14759275],\n",
       "       [0.88588153, 1.        , 0.23676038],\n",
       "       [0.14759275, 0.23676038, 1.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([similarity_matrix.values.flatten(), similarity_matrix2.values.flatten(), data.values.flatten()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
